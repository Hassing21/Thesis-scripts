{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88da6b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Loading dataset...\n",
      "✅ Loaded 30,438 articles.\n",
      "🔍 Filtering sources with < 50 articles (except 2 whitelisted)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30438/30438 [00:00<00:00, 898027.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧹 Removed 913 articles.\n",
      "✅ Remaining: 29,525 articles from 40 sources.\n",
      "💾 Saved cleaned dataset to:\n",
      "C:\\Users\\Kasper Hassing\\Desktop\\Speciale_KryptoSentiment\\data\\news_data\\bitcoin_news_timerange_filtered.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "# === File paths ===\n",
    "input_path = r\"C:\\Users\\Kasper Hassing\\Desktop\\Speciale_KryptoSentiment\\data\\news_data\\bitcoin_news_timerange.csv\"\n",
    "output_path = r\"C:\\Users\\Kasper Hassing\\Desktop\\Speciale_KryptoSentiment\\data\\news_data\\bitcoin_news_timerange_filtered.csv\"\n",
    "\n",
    "# === Load dataset ===\n",
    "print(\"📥 Loading dataset...\")\n",
    "df = pd.read_csv(input_path)\n",
    "original_count = len(df)\n",
    "print(f\"✅ Loaded {original_count:,} articles.\")\n",
    "\n",
    "# === Count articles per source ===\n",
    "source_counts = df['source'].value_counts()\n",
    "\n",
    "# === Define whitelist: sources to keep even if under 50 ===\n",
    "whitelist = ['Bitcoin Magazine', 'CoinMarketCap']\n",
    "\n",
    "# === Build final list of valid sources ===\n",
    "valid_sources = source_counts[source_counts >= 50].index.tolist() + whitelist\n",
    "valid_sources = list(set(valid_sources))  # remove duplicates\n",
    "\n",
    "# === Filter dataset ===\n",
    "print(\"🔍 Filtering sources with < 50 articles (except 2 whitelisted)...\")\n",
    "df['is_valid_source'] = df['source'].progress_apply(lambda x: x in valid_sources)\n",
    "df_filtered = df[df['is_valid_source']].drop(columns='is_valid_source')\n",
    "filtered_count = len(df_filtered)\n",
    "\n",
    "# === Report results ===\n",
    "print(f\"🧹 Removed {original_count - filtered_count:,} articles.\")\n",
    "print(f\"✅ Remaining: {filtered_count:,} articles from {df_filtered['source'].nunique()} sources.\")\n",
    "\n",
    "# === Save filtered dataset ===\n",
    "df_filtered.to_csv(output_path, index=False)\n",
    "print(f\"💾 Saved cleaned dataset to:\\n{output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
