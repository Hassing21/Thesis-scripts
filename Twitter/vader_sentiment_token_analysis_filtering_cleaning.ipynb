{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1332365",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Kasper\n",
      "[nltk_data]     Hassing\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to C:\\Users\\Kasper\n",
      "[nltk_data]     Hassing\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('vader_lexicon')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99b86555",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyserer tweets: 100%|██████████| 7853881/7853881 [01:33<00:00, 83729.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Sentimentstatistikker ===\n",
      "Gennemsnitlig VADER-score: 0.1193\n",
      "Median VADER-score: 0.0000\n",
      "Antal positive tweets: 3667190\n",
      "Antal negative tweets: 1945961\n",
      "Antal neutrale tweets: 2240730\n",
      "\n",
      "=== Hyppigste ord i alle tweets ===\n",
      "bitcoin: 8321574\n",
      "crypto: 1202014\n",
      "btc: 1145606\n",
      "cryptocurrency: 582894\n",
      "k: 539816\n",
      "ethereum: 493780\n",
      "like: 476330\n",
      "buy: 468639\n",
      "dont: 389732\n",
      "eth: 361913\n",
      "money: 349913\n",
      "price: 349407\n",
      "people: 348127\n",
      "time: 340409\n",
      "one: 324418\n",
      "get: 319272\n",
      "market: 317350\n",
      "blockchain: 306759\n",
      "would: 275108\n",
      "new: 268604\n",
      "\n",
      "=== Hyppigste ord i tweets med score 0.0 ===\n",
      "bitcoin: 2392723\n",
      "btc: 407436\n",
      "crypto: 400951\n",
      "cryptocurrency: 209325\n",
      "ethereum: 185804\n",
      "k: 176597\n",
      "buy: 148092\n",
      "eth: 138320\n",
      "price: 118428\n",
      "blockchain: 106431\n",
      "market: 92239\n",
      "time: 91891\n",
      "new: 90749\n",
      "via: 83895\n",
      "money: 79638\n",
      "dont: 75232\n",
      "get: 75103\n",
      "going: 74334\n",
      "nft: 72857\n",
      "think: 71722\n",
      "\n",
      "=== Hyppigste positive ord ===\n",
      "bitcoin: 3870064\n",
      "crypto: 546052\n",
      "btc: 491894\n",
      "like: 384778\n",
      "cryptocurrency: 268929\n",
      "k: 224278\n",
      "ethereum: 222507\n",
      "good: 210175\n",
      "buy: 208344\n",
      "dont: 189253\n",
      "money: 170945\n",
      "people: 168664\n",
      "time: 164989\n",
      "one: 164949\n",
      "get: 164197\n",
      "eth: 157526\n",
      "blockchain: 154693\n",
      "would: 153624\n",
      "im: 139036\n",
      "market: 138519\n",
      "\n",
      "=== Hyppigste negative ord ===\n",
      "bitcoin: 2058787\n",
      "crypto: 255011\n",
      "btc: 246276\n",
      "k: 138941\n",
      "dont: 125247\n",
      "people: 117202\n",
      "buy: 112203\n",
      "cryptocurrency: 104640\n",
      "money: 99330\n",
      "price: 94091\n",
      "like: 89506\n",
      "one: 88045\n",
      "market: 86592\n",
      "ethereum: 85469\n",
      "time: 83529\n",
      "get: 79972\n",
      "im: 74240\n",
      "going: 72260\n",
      "think: 71057\n",
      "would: 67909\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Indlæs en mindre sample først (fx 100.000 rækker for hurtig test)\n",
    "file_path = r\"C:\\Users\\Kasper Hassing\\Desktop\\Speciale_KryptoSentiment\\data\\twitter_posts\\bitcoin_tweets_cleaned_16_vader.csv\"\n",
    "data = pd.read_csv(file_path, nrows=8000000)  # Begrænset til 100.000 for hurtigere test\n",
    "\n",
    "# Initialiser VADER\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Brug Pandas direkte til tokenisering (hurtigere end NLTK)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = re.findall(r'\\b\\w+\\b', str(text).lower())\n",
    "    return [t for t in tokens if t not in stop_words]\n",
    "\n",
    "# Saml statistik effektivt\n",
    "all_words = Counter()\n",
    "zero_score_words = Counter()\n",
    "unrecognized_words = Counter()\n",
    "positive_words = Counter()\n",
    "negative_words = Counter()\n",
    "\n",
    "# Drop NaN-værdier før iterering for at spare tid\n",
    "data = data.dropna(subset=['text_cleaned', 'vader_sentiment_score'])\n",
    "\n",
    "# Brug Pandas til direkte gruppering af scores\n",
    "positive_count = len(data[data['vader_sentiment_score'] > 0])\n",
    "negative_count = len(data[data['vader_sentiment_score'] < 0])\n",
    "neutral_count = len(data[data['vader_sentiment_score'] == 0])\n",
    "mean_score = data['vader_sentiment_score'].mean()\n",
    "median_score = data['vader_sentiment_score'].median()\n",
    "\n",
    "# Processér tweets\n",
    "for text, score in tqdm(zip(data['text_cleaned'], data['vader_sentiment_score']), total=len(data), desc=\"Analyserer tweets\"):\n",
    "    tokens = tokenize(text)\n",
    "    all_words.update(tokens)\n",
    "\n",
    "    if score == 0.0:\n",
    "        zero_score_words.update(tokens)\n",
    "    elif score > 0:\n",
    "        positive_words.update(tokens)\n",
    "    elif score < 0:\n",
    "        negative_words.update(tokens)\n",
    "\n",
    "# Udskriv resultater\n",
    "print(f\"\\n=== Sentimentstatistikker ===\")\n",
    "print(f\"Gennemsnitlig VADER-score: {mean_score:.4f}\")\n",
    "print(f\"Median VADER-score: {median_score:.4f}\")\n",
    "print(f\"Antal positive tweets: {positive_count}\")\n",
    "print(f\"Antal negative tweets: {negative_count}\")\n",
    "print(f\"Antal neutrale tweets: {neutral_count}\")\n",
    "\n",
    "print(f\"\\n=== Hyppigste ord i alle tweets ===\")\n",
    "for word, freq in all_words.most_common(20):\n",
    "    print(f\"{word}: {freq}\")\n",
    "\n",
    "print(f\"\\n=== Hyppigste ord i tweets med score 0.0 ===\")\n",
    "for word, freq in zero_score_words.most_common(20):\n",
    "    print(f\"{word}: {freq}\")\n",
    "\n",
    "print(f\"\\n=== Hyppigste positive ord ===\")\n",
    "for word, freq in positive_words.most_common(20):\n",
    "    print(f\"{word}: {freq}\")\n",
    "\n",
    "print(f\"\\n=== Hyppigste negative ord ===\")\n",
    "for word, freq in negative_words.most_common(20):\n",
    "    print(f\"{word}: {freq}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57a8e2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyserer tweets: 100%|██████████| 100000/100000 [07:27<00:00, 223.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Mest positive ord (gennemsnitlig score) ===\n",
      "                                   Avg_VADER_Score  Count\n",
      "ygifgsnngteogbvhxsvwlzgorbh                 0.9853      1\n",
      "wellbe                                      0.9808      1\n",
      "safelambo                                   0.9783      1\n",
      "kewl                                        0.9772      1\n",
      "bcqjwwhmjedcxtllxmlntkdvfjdghkwep           0.9763      1\n",
      "waytomoon                                   0.9763      1\n",
      "ldfi                                        0.9763      1\n",
      "jobi                                        0.9758      1\n",
      "seebsc                                      0.9758      1\n",
      "qcbemdaqsmndeabnjhplomokxjzfs               0.9758      1\n",
      "sooni                                       0.9758      1\n",
      "moneyim                                     0.9758      1\n",
      "nonadjusted                                 0.9753      1\n",
      "grogu                                       0.9753      1\n",
      "xdceaeecadae                                0.9738      1\n",
      "twittwr                                     0.9728      1\n",
      "mothwrfucker                                0.9728      1\n",
      "selfmade                                    0.9722      1\n",
      "zuwlyjkchyvafaiavisskboqf                   0.9717      1\n",
      "adoring                                     0.9709      1\n",
      "\n",
      "=== Mest negative ord (gennemsnitlig score) ===\n",
      "                Avg_VADER_Score  Count\n",
      "neer                    -0.9740      1\n",
      "stolenmoney             -0.9705      1\n",
      "irritatingand           -0.9705      1\n",
      "mentalpatient           -0.9690      1\n",
      "goldstockseven          -0.9587      1\n",
      "cal                     -0.9559      1\n",
      "eprocurement            -0.9524      1\n",
      "reanimated              -0.9493      1\n",
      "irreparably             -0.9432      1\n",
      "tarnished               -0.9432      1\n",
      "herdsmen                -0.9413      1\n",
      "abducts                 -0.9413      1\n",
      "katsina                 -0.9413      1\n",
      "herdsman                -0.9413      1\n",
      "bokoharam               -0.9413      1\n",
      "mack                    -0.9393      1\n",
      "iconically              -0.9382      1\n",
      "xrpx                    -0.9371      1\n",
      "cybercrimechat          -0.9371      1\n",
      "enemys                  -0.9251      1\n",
      "\n",
      "=== Mest hyppige ord i neutrale tweets (score 0.0) ===\n",
      "              Word  Frequency\n",
      "0          bitcoin      29986\n",
      "1              btc       5052\n",
      "2           crypto       4996\n",
      "3   cryptocurrency       2643\n",
      "4         ethereum       2320\n",
      "5                k       2141\n",
      "6              buy       1833\n",
      "7              eth       1622\n",
      "8            price       1417\n",
      "9       blockchain       1294\n",
      "10          market       1221\n",
      "11            time       1166\n",
      "12             new       1126\n",
      "13           money       1046\n",
      "14             via        993\n",
      "15            dont        963\n",
      "16           going        961\n",
      "17           think        937\n",
      "18             get        928\n",
      "19             nft        918\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict, Counter\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Indlæs datasættet\n",
    "file_path = r\"C:\\Users\\Kasper Hassing\\Desktop\\Speciale_KryptoSentiment\\data\\twitter_posts\\bitcoin_tweets_cleaned_16_vader.csv\"\n",
    "data = pd.read_csv(file_path).sample(n=100_000, random_state=42)\n",
    "\n",
    "\n",
    "# Initialiser VADER\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Funktion til tokenisering\n",
    "def tokenize(text):\n",
    "    tokens = re.findall(r'\\b\\w+\\b', str(text).lower())\n",
    "    return [t for t in tokens if t not in stopwords.words('english')]\n",
    "\n",
    "# Ord-sentiment opsamling\n",
    "word_scores = defaultdict(list)\n",
    "neutral_words = Counter()\n",
    "\n",
    "# Progress bar\n",
    "for _, row in tqdm(data.iterrows(), total=len(data), desc=\"Analyserer tweets\"):\n",
    "    tokens = tokenize(row['text_cleaned'])\n",
    "    score = row['vader_sentiment_score']\n",
    "    for token in tokens:\n",
    "        word_scores[token].append(score)\n",
    "        if score == 0.0:\n",
    "            neutral_words[token] += 1\n",
    "\n",
    "# Beregn gennemsnitlig VADER-score for hvert ord\n",
    "word_avg_scores = {word: sum(scores) / len(scores) for word, scores in word_scores.items()}\n",
    "word_count = {word: len(scores) for word, scores in word_scores.items()}\n",
    "\n",
    "# Skab DataFrame for sentiment-weighted ordscore\n",
    "df_sentiment_weighted = pd.DataFrame.from_dict(word_avg_scores, orient='index', columns=['Avg_VADER_Score'])\n",
    "df_sentiment_weighted['Count'] = df_sentiment_weighted.index.map(word_count)\n",
    "\n",
    "# Sortér efter mest positive og mest negative\n",
    "df_positive = df_sentiment_weighted[df_sentiment_weighted['Avg_VADER_Score'] > 0].sort_values(by='Avg_VADER_Score', ascending=False).head(20)\n",
    "df_negative = df_sentiment_weighted[df_sentiment_weighted['Avg_VADER_Score'] < 0].sort_values(by='Avg_VADER_Score').head(20)\n",
    "\n",
    "# Hyppige neutrale ord\n",
    "df_neutral = pd.DataFrame(neutral_words.most_common(20), columns=['Word', 'Frequency'])\n",
    "\n",
    "# Udskriv resultater\n",
    "print(\"\\n=== Mest positive ord (gennemsnitlig score) ===\")\n",
    "print(df_positive)\n",
    "\n",
    "print(\"\\n=== Mest negative ord (gennemsnitlig score) ===\")\n",
    "print(df_negative)\n",
    "\n",
    "print(\"\\n=== Mest hyppige ord i neutrale tweets (score 0.0) ===\")\n",
    "print(df_neutral)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d9a8460",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyserer tweets: 100%|██████████| 100000/100000 [07:13<00:00, 230.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Mest positive ord (uanset frekvens) ===\n",
      "                                           Avg_VADER_Score  Count\n",
      "ygifgsnngteogbvhxsvwlzgorbh                         0.9853      1\n",
      "wellbe                                              0.9808      1\n",
      "safelambo                                           0.9783      1\n",
      "kewl                                                0.9772      1\n",
      "bitcoin bcqjwwhmjedcxtllxmlntkdvfjdghkwep           0.9763      1\n",
      "ldfi                                                0.9763      1\n",
      "waytomoon                                           0.9763      1\n",
      "bcqjwwhmjedcxtllxmlntkdvfjdghkwep                   0.9763      1\n",
      "bitcoin ldfi                                        0.9763      1\n",
      "qcbemdaqsmndeabnjhplomokxjzfs                       0.9758      1\n",
      "bitcoin loveyou                                     0.9758      1\n",
      "moneyim                                             0.9758      1\n",
      "sooni                                               0.9758      1\n",
      "jobi                                                0.9758      1\n",
      "seebsc                                              0.9758      1\n",
      "qcbemdaqsmndeabnjhplomokxjzfs bitcoin               0.9758      1\n",
      "nonadjusted                                         0.9753      1\n",
      "grogu                                               0.9753      1\n",
      "grogu bitcoin                                       0.9753      1\n",
      "xdceaeecadae                                        0.9738      1\n",
      "\n",
      "=== Mest positive ord (mindst 100 forekomster) ===\n",
      "                 Avg_VADER_Score  Count\n",
      "excellent               0.758652    145\n",
      "awesome                 0.736380    227\n",
      "wonderful               0.731241    104\n",
      "congratulations         0.727254    136\n",
      "beautiful               0.707428    163\n",
      "success                 0.699004    314\n",
      "great                   0.692697   1766\n",
      "luck                    0.683070    247\n",
      "best                    0.680781   1496\n",
      "amazing                 0.680370    427\n",
      "bitcoin best            0.678438    134\n",
      "project                 0.672568   1758\n",
      "gift                    0.662051    167\n",
      "promising               0.661453    118\n",
      "successful              0.659995    169\n",
      "congrats                0.651488    107\n",
      "freedom                 0.647771    468\n",
      "love                    0.645413   1285\n",
      "bitcoin great           0.636927    106\n",
      "greatest                0.631970    115\n",
      "\n",
      "=== Mest negative ord (uanset frekvens) ===\n",
      "                        Avg_VADER_Score  Count\n",
      "neer                            -0.9740      1\n",
      "irritatingand                   -0.9705      1\n",
      "stolenmoney                     -0.9705      1\n",
      "mentalpatient                   -0.9690      1\n",
      "goldstockseven bitcoin          -0.9587      1\n",
      "goldstockseven                  -0.9587      1\n",
      "cal                             -0.9559      1\n",
      "karnataka bitcoin               -0.9524      1\n",
      "eprocurement                    -0.9524      1\n",
      "reanimated                      -0.9493      1\n",
      "tarnished                       -0.9432      1\n",
      "irreparably                     -0.9432      1\n",
      "bokoharam bitcoin               -0.9413      1\n",
      "bokoharam                       -0.9413      1\n",
      "katsina                         -0.9413      1\n",
      "abducts                         -0.9413      1\n",
      "bitcoin terrorism               -0.9413      1\n",
      "herdsman                        -0.9413      1\n",
      "herdsmen                        -0.9413      1\n",
      "mack                            -0.9393      1\n",
      "\n",
      "=== Mest negative ord (mindst 100 forekomster) ===\n",
      "              Avg_VADER_Score  Count\n",
      "death               -0.576770    124\n",
      "hell                -0.556196    237\n",
      "scams               -0.517918    121\n",
      "worst               -0.514825    191\n",
      "wtf                 -0.510841    148\n",
      "bitcoin scam        -0.508630    149\n",
      "dead                -0.502803    326\n",
      "bullshit            -0.497024    122\n",
      "crisis              -0.488422    128\n",
      "fraud               -0.469042    148\n",
      "ass                 -0.467012    154\n",
      "scam                -0.460325    600\n",
      "fear                -0.455735    316\n",
      "riot                -0.444451    186\n",
      "greed               -0.443572    153\n",
      "war                 -0.438265    296\n",
      "die                 -0.427804    191\n",
      "illegal             -0.426810    135\n",
      "kill                -0.415272    130\n",
      "collapse            -0.393174    166\n",
      "\n",
      "=== Mest brugte kombinerede bitcoin-ord ===\n",
      "                    Phrase  Frequency\n",
      "0              bitcoin btc       3042\n",
      "1         bitcoin ethereum       2580\n",
      "2              buy bitcoin       2296\n",
      "3              btc bitcoin       2268\n",
      "4           bitcoin crypto       2146\n",
      "5           crypto bitcoin       1739\n",
      "6           bitcoin mining       1263\n",
      "7   bitcoin cryptocurrency       1259\n",
      "8          bitcoin bitcoin       1184\n",
      "9            bitcoin price       1173\n",
      "10  cryptocurrency bitcoin        987\n",
      "11            like bitcoin        951\n",
      "12             bitcoin eth        841\n",
      "13               bitcoin k        770\n",
      "14            bitcoin news        740\n",
      "15          buying bitcoin        670\n",
      "16               k bitcoin        604\n",
      "17          bought bitcoin        593\n",
      "18           bitcoin going        576\n",
      "19      bitcoin blockchain        517\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict, Counter\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Indlæs datasættet\n",
    "file_path = r\"C:\\Users\\Kasper Hassing\\Desktop\\Speciale_KryptoSentiment\\data\\twitter_posts\\bitcoin_tweets_cleaned_16_vader.csv\"\n",
    "data = pd.read_csv(file_path).sample(n=100_000, random_state=42)\n",
    "\n",
    "# Initialiser VADER\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Funktion til tokenisering\n",
    "def tokenize(text):\n",
    "    tokens = re.findall(r'\\b\\w+\\b', str(text).lower())\n",
    "    return [t for t in tokens if t not in stopwords.words('english')]\n",
    "\n",
    "# Saml statistik\n",
    "word_scores = defaultdict(list)\n",
    "neutral_words = Counter()\n",
    "combined_phrases = Counter()\n",
    "\n",
    "# Progress bar\n",
    "for _, row in tqdm(data.iterrows(), total=len(data), desc=\"Analyserer tweets\"):\n",
    "    tokens = tokenize(row['text_cleaned'])\n",
    "    score = row['vader_sentiment_score']\n",
    "\n",
    "    for i, token in enumerate(tokens):\n",
    "        word_scores[token].append(score)\n",
    "\n",
    "        # Kombination af ordpar med \"bitcoin\"\n",
    "        if token == \"bitcoin\":\n",
    "            if i > 0:  # Ord før \"bitcoin\"\n",
    "                phrase = f\"{tokens[i-1]} bitcoin\"\n",
    "                combined_phrases[phrase] += 1\n",
    "                word_scores[phrase].append(score)\n",
    "            if i < len(tokens) - 1:  # Ord efter \"bitcoin\"\n",
    "                phrase = f\"bitcoin {tokens[i+1]}\"\n",
    "                combined_phrases[phrase] += 1\n",
    "                word_scores[phrase].append(score)\n",
    "\n",
    "        # Neutrale ord\n",
    "        if score == 0.0:\n",
    "            neutral_words[token] += 1\n",
    "\n",
    "# Beregn gennemsnitlig VADER-score for hvert ord\n",
    "word_avg_scores = {word: sum(scores) / len(scores) for word, scores in word_scores.items()}\n",
    "word_count = {word: len(scores) for word, scores in word_scores.items()}\n",
    "\n",
    "# Ufiltreret ordliste\n",
    "df_sentiment_weighted_all = pd.DataFrame.from_dict(word_avg_scores, orient='index', columns=['Avg_VADER_Score'])\n",
    "df_sentiment_weighted_all['Count'] = df_sentiment_weighted_all.index.map(word_count)\n",
    "\n",
    "# Filtreret ordliste (mindst 100 forekomster)\n",
    "filtered_scores = {word: score for word, score in word_avg_scores.items() if word_count[word] >= 100}\n",
    "df_sentiment_weighted_filtered = pd.DataFrame.from_dict(filtered_scores, orient='index', columns=['Avg_VADER_Score'])\n",
    "df_sentiment_weighted_filtered['Count'] = df_sentiment_weighted_filtered.index.map(word_count)\n",
    "\n",
    "# Sortér begge efter mest positive og mest negative\n",
    "df_positive_all = df_sentiment_weighted_all[df_sentiment_weighted_all['Avg_VADER_Score'] > 0].sort_values(by='Avg_VADER_Score', ascending=False).head(20)\n",
    "df_negative_all = df_sentiment_weighted_all[df_sentiment_weighted_all['Avg_VADER_Score'] < 0].sort_values(by='Avg_VADER_Score').head(20)\n",
    "\n",
    "df_positive_filtered = df_sentiment_weighted_filtered[df_sentiment_weighted_filtered['Avg_VADER_Score'] > 0].sort_values(by='Avg_VADER_Score', ascending=False).head(20)\n",
    "df_negative_filtered = df_sentiment_weighted_filtered[df_sentiment_weighted_filtered['Avg_VADER_Score'] < 0].sort_values(by='Avg_VADER_Score').head(20)\n",
    "\n",
    "# Mest brugte kombinerede bitcoin-ord\n",
    "df_combined = pd.DataFrame(combined_phrases.most_common(20), columns=['Phrase', 'Frequency'])\n",
    "\n",
    "# Udskriv resultater\n",
    "print(\"\\n=== Mest positive ord (uanset frekvens) ===\")\n",
    "print(df_positive_all)\n",
    "\n",
    "print(\"\\n=== Mest positive ord (mindst 100 forekomster) ===\")\n",
    "print(df_positive_filtered)\n",
    "\n",
    "print(\"\\n=== Mest negative ord (uanset frekvens) ===\")\n",
    "print(df_negative_all)\n",
    "\n",
    "print(\"\\n=== Mest negative ord (mindst 100 forekomster) ===\")\n",
    "print(df_negative_filtered)\n",
    "\n",
    "print(\"\\n=== Mest brugte kombinerede bitcoin-ord ===\")\n",
    "print(df_combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e40d61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Renser tweets (max 15 tegn): 100%|██████████| 7853881/7853881 [01:02<00:00, 126514.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antal tweets før rensning: 7853881\n",
      "Antal tweets efter rensning: 7102781\n",
      "Antal fjernede tweets: 751100\n",
      "✅ Renset fil gemt som: C:\\Users\\Kasper Hassing\\Desktop\\Speciale_KryptoSentiment\\data\\twitter_posts\\bitcoin_tweets_cleaned_17_vader.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "# Oprindelig og ny filsti\n",
    "input_path = r\"C:\\Users\\Kasper Hassing\\Desktop\\Speciale_KryptoSentiment\\data\\twitter_posts\\bitcoin_tweets_cleaned_16_vader.csv\"\n",
    "output_path = r\"C:\\Users\\Kasper Hassing\\Desktop\\Speciale_KryptoSentiment\\data\\twitter_posts\\bitcoin_tweets_cleaned_17_vader.csv\"\n",
    "\n",
    "# Indlæs data\n",
    "data = pd.read_csv(input_path)\n",
    "\n",
    "# Valideringsfunktion (opdateret til max 15 tegn pr. ord)\n",
    "def is_valid_tweet(text):\n",
    "    tokens = re.findall(r'\\b\\w+\\b', str(text).lower())\n",
    "    if any(len(word) > 15 for word in tokens):\n",
    "        return False\n",
    "    if len(tokens) < 10:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# Anvend filtrering med progress bar\n",
    "tqdm.pandas(desc=\"Renser tweets (max 15 tegn)\")\n",
    "cleaned_data = data[data['text_cleaned'].progress_apply(is_valid_tweet)]\n",
    "\n",
    "# Statistik\n",
    "original_count = len(data)\n",
    "cleaned_count = len(cleaned_data)\n",
    "removed_count = original_count - cleaned_count\n",
    "\n",
    "print(f\"Antal tweets før rensning: {original_count}\")\n",
    "print(f\"Antal tweets efter rensning: {cleaned_count}\")\n",
    "print(f\"Antal fjernede tweets: {removed_count}\")\n",
    "\n",
    "# Gem til ny fil\n",
    "cleaned_data.to_csv(output_path, index=False)\n",
    "print(f\"✅ Renset fil gemt som: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89ddb841",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tjekker for emojis: 100%|██████████| 7102781/7102781 [00:26<00:00, 270943.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antal tweets med emojis: 0\n",
      "Samlet antal tweets: 7102781\n",
      "Andel tweets med emojis: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Emoji regex\n",
    "emoji_pattern = re.compile(\n",
    "    r\"[\\U0001F600-\\U0001F64F]|\"  # Emoticons\n",
    "    r\"[\\U0001F300-\\U0001F5FF]|\"  # Symboler og piktogrammer\n",
    "    r\"[\\U0001F680-\\U0001F6FF]|\"  # Transport og kortsymboler\n",
    "    r\"[\\U0001F700-\\U0001F77F]|\"  # Diverse symboler\n",
    "    r\"[\\U0001F780-\\U0001F7FF]|\"  # Geometriske symboler\n",
    "    r\"[\\U0001F800-\\U0001F8FF]|\"  # Supplerende symboler\n",
    "    r\"[\\U0001F900-\\U0001F9FF]|\"  # Ansigts-symboler og kropsdele\n",
    "    r\"[\\U0001FA00-\\U0001FA6F]|\"  # Objekter og ting\n",
    "    r\"[\\U0001FA70-\\U0001FAFF]|\"  # Diverse symboler og piktogrammer\n",
    "    r\"[\\U00002702-\\U000027B0]|\"  # Andre symboler og pile\n",
    "    r\"[\\U000024C2-\\U0001F251]\",  # Diverse symboler og pile\n",
    "    flags=re.UNICODE\n",
    ")\n",
    "\n",
    "# Funktion til at tjekke for emojis\n",
    "def contains_emoji(text):\n",
    "    return bool(emoji_pattern.search(str(text)))\n",
    "\n",
    "# Filsti til data\n",
    "file_path = r\"C:\\Users\\Kasper Hassing\\Desktop\\Speciale_KryptoSentiment\\data\\twitter_posts\\bitcoin_tweets_cleaned_17_vader.csv\"\n",
    "\n",
    "# Indlæs data\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Anvend emoji-tjek\n",
    "tqdm.pandas(desc=\"Tjekker for emojis\")\n",
    "data['contains_emoji'] = data['text_cleaned'].progress_apply(contains_emoji)\n",
    "\n",
    "# Udskriv resultat\n",
    "emoji_count = data['contains_emoji'].sum()\n",
    "total_count = len(data)\n",
    "print(f\"Antal tweets med emojis: {emoji_count}\")\n",
    "print(f\"Samlet antal tweets: {total_count}\")\n",
    "print(f\"Andel tweets med emojis: {emoji_count / total_count:.2%}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
